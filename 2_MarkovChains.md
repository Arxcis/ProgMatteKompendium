[TOC]

# 2. Markov Chains

A Markov Chain is a *network* with these two properties:

1. The weight of each edge represents a probability, and the value of the weights is in the range [0â€¦1].
2. The sum of all the weights leaving a node is **1**.

## 2.1 States and chains

The nodes in a Markov Chain are called states. A state can be in two different modes.

**Transient state** -

**Absorbing state** -

**Absorbing chain** - 

**Ergodic chain** -

## 2.2 The Stochastic Matrix

**Matrix blocks [Q, 0, R, I]** - 

## 2.3 The Fundamental Matrix N

**N\[i][j]** - 

**RN\[i][j]** -

**cN\[i][j]** -

## 2.4 Matrix calculations with [Numpy & Python] and [Eigen & C++]